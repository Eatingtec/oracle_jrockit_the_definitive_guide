<a name="6.1" />
# 6.1 相关背景

起初，JRockit Mission Control只是JRockit开发团队用来对JRockit JVM进行监控和调试的内部工具集。这些分析工具本身并非为用户而开发，不过在为用户解决了不少高端问题后，顿时威名远扬，同时开发团队意识到，这些工具对用户分析其应用程序是很有帮助的，于是他们将这些分析工具做得更加易用，更具模块性，并作为Java相关工具随JRockit JDK一起发布，这就是后来的JRockit Mission Control。

如今，JRockit Mission Control套件集监控、管理和分析功能于一身，还可以跟踪分析内存泄漏。它能够以非常小的执行开销获取到应用程序的运行时数据，相比之下，大部分其他的分析工具都会使用应用程序严重拖慢应用程序的运行，因而改变了应用程序原有的行为。正如在第5章中提到的，如果分析工具的执行开销过大，那么最终观测到的就不是应用程序真实的行为了，而是应用程序和分析工具共同作用的结果。

>由于做性能分析而改变应用程序运行行为的现象可以归为 [**观察者效应**][1]，即观察者的行为改变了被观察者的行为。有时，也称观察者效应为[**海森堡效应**][2]，或统称为[**海森堡不确定性原理**][3]。
>
>在BEA被Oracle收购之前，BEA的性能团队内部层使用不同的性能分析工具。为了使WebLogic服务器上J2EE应用程序的基准测试更加精确，性能团队一直在寻找执行开销较低的分析工具，他们筛选出几种不同的分析工具，并通过基准测试计算了性能分析工具的执行开销，结果显示Mission Control的执行开销是0.5%，测试结果中排名第二的是另一款比较著名的Java分析器，但其执行开销却高达93.8%。
>
>译者注，作为扩展内容，关于海森堡不确定性原理，推荐阅读[《上帝掷骰子吗-量子物理史话》][4]。

<a name="6.1.1" />
## 6.1.1 采样分析 vs. 准确分析

Naturally, different tools have different strengths and weaknesses. The data
captured by JRockit Mission Control aims to provide a statistically accurate
representation of what is going on in the JRockit JVM. It will not always be exact,
but it will usually provide the information required to solve important problems.
We call this sampling-based profiling. Sampling-based profiling lends itself well
to when a statistical approach can be used to periodically record a state. The most
common variants in JRockit Mission Control are time-based sampling and sampling
based on a subset of state changes. The JVM, being a large state machine, can cheaply
provide a large amount of samples and events. The data can be readily exposed by
the JVM to a consumer, for example Mission Control. Sampling-based profiling has
the additional benefit that it is much easier to estimate the profiling overhead.

一般来说，不同的工具有不同的适用场景，JRockit Mission Control所收集到的数据只是在统计学意义上，准确展示出当前JRockit JVM当前的运行状态，虽然并非完全准确，但也可以为解决各种问题提供必要的信息了。这种分析方式成为 **采样分析（sampling-based profiling）**。

For example, the best way to find out where an application is spending the most
execution time is to use the JRockit Flight Recorder tool to look at the hot methods list.
The list provides a statistically representative view of what methods JRockit spent the
most time executing, using information from the code profiling thread in the JRockit
code generator. It will, however, not provide information about every single method
call or exactly how much wall clock time was spent executing the method.

There are some exact profiling alternatives in JRockit Mission Control, as well, that
can provide such metrics. These, however, may incur a much larger overhead if
enabled. It is, for instance, possible (but please don't try this at home) to connect the
JRockit Management Console to a running application and enable exact timing and
invocation counters for each and every method in the system. Doing exact profiling
always incurs extra runtime overhead. Enabling exact profiling for every method
in the system will require the JVM to both generate and execute a large amount of
extra profiling code. This will not only adversely affect performance, but it is also
quite difficult to determine the exact performance implications. Some of the JRockit
code is written in Java. Instrumenting all allocation and locking code would almost
certainly bring the application to its knees. If the aim is to determine what parts of
the application would benefit most from improvements and optimization, the
sampling-based approach is superior.

One might think that the cost of overhead for exact profiling is paid for in better
measurements. For example, given exact data, the timing values for all the methods
in the system can then be measured, and the one with the highest invocation count
multiplied by execution time would be the natural one to target for optimization
first, wouldn't it?

It might, but in a sufficiently complex system the data will be misleading and
distorted. The overhead of the methods on the critical paths in the system will
quite likely increase drastically and the overall system performance will degrade.
Furthermore, applying the exact method profiler to every single method in the
system would most likely severely change the behavior of the application,
rendering the measurements inaccurate

>Using the JRockit Mission Control Management Console to retrieve exact
method timings and invocation counts is one of the rare cases where the
overhead of running the JRockit tools suite is very difficult to estimate.
The time it takes to calculate the profiling data can be considered to
be constant. Invocation counting code is mainly placed at method
entries and method exits. So, the distortion caused by the profiling
is proportional to how often the method is invoked and inversely
proportional to the time the method takes to execute. If the method is
frequently called, the overhead will add up. If the method already takes
a long time to execute, the overhead may be less noticeable. In multi-
threaded scenarios, the non-determinism of exact profiling with the
Management Console is even greater.




[1]:    http://en.wikipedia.org/wiki/Observer_effect_(physics)
[2]:    https://en.wikipedia.org/wiki/Heisenberg_effect
[3]:    https://en.wikipedia.org/wiki/Uncertainty_principle
[4]:    http://book.douban.com/subject/1467022/