# 4.4 对于线程与同步的优化

本节将会对自适应运行时环境中线程和同步操作方面的优化进行介绍。

<a name="4.4.1" />
## 4.4.1 锁膨胀与锁收缩

正如之前介绍锁时提到的，自适应运行时系统需要能够当前系统负载和线程竞争情况在胖锁和瘦锁之间切换执行，这里就涉及到代码生成器和锁的具体实现。

在自适应环境中可以以很小的开销得到锁的运行信息（如果要做完整的锁分析则会有一些性能开销），当线程获取/释放某个锁时，运行时系统可以记录下是哪个线程获得了锁，获取锁时的竞争情况。所以，如果某个线程尝试了很多次还无法获取到锁，运行时就可以考虑将该瘦锁调整为胖锁。胖锁更适合竞争激烈的场景，不再让线程自旋，而挂起被阻塞住的线程，这样可以节省对CPU资源的浪费。这种瘦锁到胖锁的转换称为 **锁膨胀（lock inflation）**。

>默认情况下，即使瘦锁已经膨胀为胖锁，JRockit也是使用一个小的自旋锁来实现胖锁的。乍看之下，这不太符合常理，但这么做确实是很有益处的。如果锁的竞争确实非常激烈，而导致线程长时间自旋的话，可以使用命令行参数`-XX:UseFatSpin=false`可以禁用此方式。作为胖锁的一部分，自旋锁也可以利用到自适应运行时获取到的反馈信息，这部分功能默认是禁用的，可以使用命令行参数`-XX:UseAdaptiveFatSpin=true`来开启。

类似的，在完成了一系列解锁操作之后，如果锁队列和等待队列中都是空的，这时就可以考虑将胖锁再转换为瘦锁了，这称为 **锁收缩（lock deflation）**。

JRockit使用了启发式算法来执行锁膨胀和锁收缩，因此对于某个应用程序来说，锁的行为会根据线程对锁的竞争情况而改变。

如果需要的话，可以通过命令行参数来改变用于切换胖锁和瘦锁的启发式算法，但通常不建议这样做，[下一章][1]会对此做简要介绍。

<a name="4.4.2" />
## 4.4.2 递归锁

同一个线程可以对同一个对象加锁数次，这就是所谓的 **递归锁（recursive lock）**，尽管没必要，但这么做确实是合法的，例如，当某个会执行加锁操作的方法被内联到对同一个对象加锁的方法中，或者某个同步方法被递归调用，这时就会出现递归锁。如果关键区代码中没有危险代码（例如在内部锁和外部锁之间访问`volatile`变量，或发生对象逃逸），则代码生成器可以考虑将内部的锁彻底移除。

JRockit使用了一个专门的锁符号位（lock token bit）来标识递归锁。当某个锁被某个线程获取到至少两次以上，而且没有释放最外层的锁，则该锁会被标记为递归锁。当发生异常时，运行时会重置递归标记，正确抛出异常，不会带来什么额外的同步操作的开销。

<a name="4.4.3" />
## 4.4.3 锁融合

The JRockit optimizing JIT compiler also uses a code optimization called lock fusion
(sometimes also referred to as lock coarsening in literature). When inlining plenty of
code, especially synchronized methods, the observation can be made that frequent
sequential locks and unlocks with the same monitor object are common.

在JRockit中，JIT优化编译器还使用了一种名为 **锁融合（lock fusion）**的代码优化技术，在某些文档中也称为 [**锁粗化（lock coarsening）**][2]。当编译器将很多方法内联到一起后，尤其是将多个同步方法内联到一起后，可能会出现多个代码块按顺序对同一个监视器对象重复执行加锁和解锁操作。

Consider code that, after inlining, looks like:
以下面的代码为例：

    synchronized(x) {
        //Do something...
    }
    
    //Short snippet of code...
    x = y;
    
    synchronized(y) {
        //Do something else...
    }

[别名分析][3]可以判断出`x`和`y`实际上是同一个对象。如果两个同步代码块之间的代码的执行开销非常小，而且比释放锁再获取锁的开销还小的话，则代码生成器就可以考虑将两个同步代码块合并到一起，如下所示：


    synchronized(x) {
        //Do something...
        //Short snippet of code...
        x = y;
        //Do something else...
    }

当然，执行锁融合的前提是两个同步代码块之间的代码中不能有对`volatile`变量的访问，也不能发生对象逃逸，更不能使融合后的代码违反Java内存模型的语义。除了上述问题之外，还有一些其他可能因优化产生的问题需要处理，例如锁融合后对异常的处理需要考虑相互之间的兼容性，因其超出本章范围，不再赘述。

将所有的代码块都融合到一起显然不是什么好主意，但如果能够正确的挑选必要的代码块进行如何的话，还是很有裨益的。如果能过获得足够多的采样信息，就能够更准确的判断是否要执行融合锁操作。

总归一句话，上述代码优化的主要目的是避免不必要的锁释放操作。其实，不借助代码生成器，线程系统本身可以通过状态机来实现类似的优化，即所谓的 **延迟解锁（lazy unlocking）**。

<a name="4.4.4" />
## 4.4.4 延迟解锁

当系统中有很多会降低程序执行效率的、线程局部的解锁和重新加锁的操作时，会有什么影响？这是否是程序运行的常态？运行时是否可以假设每个单独的解锁操作实际上都是不必要的？

如果某个锁每次被释放后又立刻都被同一个线程获取到，则运行时可以做上述假设。但只要有另外某个线程试图获取这个看起来像是未被加锁的监视器对象（这种情况是符合语义的），这种假设就不再成立了。这时为了使这个监视器对象看起来 **像是一切正常**，原本持有该监视器对象的线程需要强行释放该锁。这种实现方式称为 **延迟解锁（lazy locking）**，在某些描述中也称为 [**偏向锁（biased locking）**][4]。

即使某个锁完全没有竞争，执行加锁和解锁操作的开销仍旧比什么都不做要大。而使用原子指令会使该指令周围的Java代码都产生额外的执行开销。

在Java环境中，有时确实可以假设大部分锁都只在线程局部内起作用。第三方代码为了完成线程局部内的操作有时会使用不必要的同步操作，这是因为第三方库的作者无法知晓其代码是否会被用在并行环境中，除非显式的指定代码不是线程安全的，否则就不得不使用同步操作。JDK本身也有很多这样的例子，典型的就是`java.util.Vector`类的实现。如果程序员要在线程局部环境中使用向量，但却没有考虑清楚的话，就有可能会使用`java.util.Vector`类，事实上，`java.util.ArrayList`类可以完成同样的任务，还不会有同步操作带来的额外开销。

从上面的介绍可以看出，假设大部分锁都只在线程局部起作用而不会出现竞争情况，是有道理的，在这种情况下，使用延迟解锁的优化方式是可以提升系统性能的。当然，天下没有免费的午餐，如果某个线程试图获取某个已经延迟解锁优化的监视器对象，这时的执行开销会被直接获取普通监视器对象大得多，因为这个看似未加锁的监视器对象必须要先被强行释放掉。

因此，假设解锁操作不再必要并不总是正确的，需要对不同的运行时行为做针对性的优化。

<a name="4.4.4.1" />
### 4.4.4.1 实现

The semantics of a lazy unlocking implementation are fairly simple.

For the lock operation,  monitorenter :

* If the object is unlocked, the thread that locks the object will reserve the lock, tagging the object as lazily locked.
* If the object is already tagged as lazily locked:
    * If the lock is wanted by the same thread, do nothing (inprinciple a recursive lock).
    * If the lock is wanted by another thread, we need to stop thethread holding the lock, detect the "real" locking state ofthe object, i.e. is it locked or unlocked. This is done with an expensive stack walk. If the object is locked, it is converted toa thin lock, otherwise it is forcefully unlocked so that it can be acquired by the new thread.

For the unlock operation,  monitorexit :

* Do nothing for a lazily locked object and leave the object in a locked state, that is, perform lazy unlocking.

In order to revoke a reservation for a thread that wants the lock, the thread that did
the reservation needs to be stopped. This is extremely expensive. The actual state of
the lock to be released is determined by inspecting the thread stack for lock tokens.
This is similar to the approach of handling unmatched locks described earlier. Lazy
unlocking uses a lock token of its own, whose bit configuration means "this object is
lazily locked".

If we never had to revert a lazy locked object, that is if all our locks are in fact thread
local, all would be well and we would see immense performance gains. In the real
world, however, we cannot afford to take the very steep penalty of releasing lazy
locked objects time and time again, if our guess proves to be wrong. So, we have to
keep track of the number of times a lazy lock is transferred between threads—the
number of penalties incurred. This information is stored in the lock word of the
monitor object in the so called transfer bits.

If the number of transfers between threads is too large, a particular object or its entire
type (class) and all its instances can be forbidden from further lazy locking and will
just be locked and unlocked normally using standard thin and fat lock mechanisms.








[1]:    ../chap5/5.md
[2]:    http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.2
[3]:    http://en.wikipedia.org/wiki/Alias_analysis
[4]:    http://www.oracle.com/technetwork/java/6-performance-137236.html#2.1.1